### –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –¥—Ä–µ–≤–Ω–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ –º–µ—Ç–æ–¥–æ–º –∫—Ä–∏–ø—Ç–æ—Ç–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞

#### –ê–ª–≥–æ—Ä–∏—Ç–º "Lingua Hypercube Decoder"

```python
import numpy as np
from scipy.spatial import Delaunay
from sklearn.manifold import Isomap
from transformers import AutoTokenizer, AutoModel
import torch
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

class AncientTextDecoder:
    def __init__(self, reference_lang="grc", modern_lang="el"):
        """
        :param reference_lang: ISO-–∫–æ–¥ –¥—Ä–µ–≤–Ω–µ–≥–æ —è–∑—ã–∫–∞ (grc - –¥—Ä–µ–≤–Ω–µ–≥—Ä–µ—á–µ—Å–∫–∏–π)
        :param modern_lang: ISO-–∫–æ–¥ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–æ—Ç–æ–º–∫–∞ (el - –≥—Ä–µ—á–µ—Å–∫–∏–π)
        """
        self.tokenizer = AutoTokenizer.from_pretrained("xlm-roberta-base")
        self.model = AutoModel.from_pretrained("xlm-roberta-base")
        self.reference_hypercubes = self.load_reference_data(reference_lang, modern_lang)
        
    def load_reference_data(self, lang_old, lang_new):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∫–æ—Ä–ø—É—Å–∞ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –≥–∏–ø–µ—Ä–∫—É–±–æ–≤"""
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—É–¥—É—Ç –Ω–∞—Å—Ç–æ—è—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        return {
            "symbol_freq": np.random.rand(100, 10),
            "syntax_graph": self.generate_synthetic_topology(),
            "semantic_field": np.load(f"data/{lang_old}_{lang_new}_semantic.npy")
        }
    
    def generate_synthetic_topology(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫—É—é —Ç–æ–ø–æ–ª–æ–≥–∏—é —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏—Ö —Å–≤—è–∑–µ–π"""
        points = np.random.rand(50, 3)
        tri = Delaunay(points[:, :2])
        return {
            "points": points,
            "simplices": tri.simplices,
            "betti": [1, 2, 1]  # B‚ÇÄ=1, B‚ÇÅ=2, B‚ÇÇ=1
        }
    
    def text_to_hypercube(self, text):
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ —Ç–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –≥–∏–ø–µ—Ä–∫—É–±"""
        # –®–∞–≥ 1: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –≤–ª–æ–∂–µ–Ω–∏–µ
        inputs = self.tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
        with torch.no_grad():
            outputs = self.model(**inputs)
        embeddings = outputs.last_hidden_state.mean(dim=1).numpy()
        
        # –®–∞–≥ 2: –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–π –≥—Ä–∞—Ñ
        syntax_graph = self.build_syntax_graph(text)
        
        # –®–∞–≥ 3: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏–º–≤–æ–ª–æ–≤
        char_freq = self.calculate_char_frequency(text)
        
        # –®–∞–≥ 4: –¢–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è
        hypercube = self.project_to_topology(embeddings, syntax_graph, char_freq)
        return hypercube
    
    def build_syntax_graph(self, text):
        """–°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (—É–ø—Ä–æ—â–µ–Ω–Ω–æ)"""
        words = text.split()
        points = np.random.rand(len(words), 3)
        tri = Delaunay(points[:, :2])
        return {
            "nodes": words,
            "points": points,
            "edges": [(i, j) for simplex in tri.simplices for i, j in zip(simplex, np.roll(simplex, 1))]
        }
    
    def calculate_char_frequency(self, text):
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Å–∏–º–≤–æ–ª–æ–≤"""
        chars = sorted(set(text))
        freq = np.array([text.count(c) for c in chars]) / len(text)
        return {"chars": chars, "freq": freq}
    
    def project_to_topology(self, semantic, syntax, char_freq):
        """–ü—Ä–æ–µ—Ü–∏—Ä—É–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤ –µ–¥–∏–Ω—ã–π —Ç–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –≥–∏–ø–µ—Ä–∫—É–±"""
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–µ —à–∫–∞–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
        combined = np.concatenate([
            semantic.flatten(),
            syntax["points"].flatten(),
            char_freq["freq"]
        ])
        
        # –£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ç–æ–ø–æ–ª–æ–≥–∏–∏
        embedding = Isomap(n_components=3, n_neighbors=5).fit_transform(combined.reshape(1, -1))
        return embedding
    
    def decode_text(self, unknown_text, reference_texts):
        """–†–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞–µ—Ç –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–µ–∫—Å—Ç"""
        unknown_cube = self.text_to_hypercube(unknown_text)
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ —Ç–µ–∫—Å—Ç–∞–º–∏
        similarities = []
        for lang, ref_data in self.reference_hypercubes.items():
            # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ç–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º–∏ –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏
            dist = self.topological_distance(unknown_cube, ref_data)
            similarities.append((lang, dist))
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏
        similarities.sort(key=lambda x: x[1])
        
        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ–≥–æ —è–∑—ã–∫–∞
        probable_lang = similarities[0][0]
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–∏–ø–æ—Ç–µ–∑—ã –ø–µ—Ä–µ–≤–æ–¥–∞
        hypothesis = self.generate_translation_hypothesis(unknown_text, probable_lang)
        
        return {
            "probable_language": probable_lang,
            "similarity_scores": similarities,
            "translation_hypothesis": hypothesis,
            "topological_features": self.extract_features(unknown_cube)
        }
    
    def topological_distance(self, cube1, cube2):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ç–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –≥–∏–ø–µ—Ä–∫—É–±–∞–º–∏"""
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ:
        # 1. –≠–π–ª–µ—Ä–æ–≤–æ–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–µ
        # 2. –ß–∏—Å–ª–∞–º –ë–µ—Ç—Ç–∏
        # 3. –§—Ä–∞–∫—Ç–∞–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        return np.linalg.norm(cube1 - np.mean(cube2))
    
    def generate_translation_hypothesis(self, text, target_lang):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥–∏–ø–æ—Ç–µ–∑—É –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–æ–ø–æ–ª–æ–≥–∏–∏"""
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–∞—è –º–æ–¥–µ–ª—å
        mapping = {
            "ê§Ä": "Œ±", "ê§Å": "Œ≤", "ê§Ç": "Œ≥",  # –§–∏–Ω–∏–∫–∏–π—Å–∫–∏–π ‚Üí –ì—Ä–µ—á–µ—Å–∫–∏–π
            "ìÄÄ": "Œ¨ŒΩŒ∏œÅœâœÄŒøœÇ", "ìÇß": "œÄœåŒªŒµŒºŒøœÇ"  # –ï–≥–∏–ø–µ—Ç—Å–∫–∏–π ‚Üí –ì—Ä–µ—á–µ—Å–∫–∏–π
        }
        return "".join(mapping.get(c, c) for c in text)
    
    def extract_features(self, hypercube):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏"""
        return {
            "euler_characteristic": self.calculate_euler(hypercube),
            "fractal_dimension": self.calculate_fractal_dim(hypercube),
            "curvature_profile": self.calculate_curvature(hypercube)
        }
    
    def calculate_euler(self, cube):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —ç–π–ª–µ—Ä–æ–≤—É —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫—É"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç –¥–ª—è 3D
        vertices = cube.shape[0]
        edges = vertices * (vertices - 1) // 2
        faces = vertices * (vertices - 1) * (vertices - 2) // 6
        return vertices - edges + faces
    
    def calculate_fractal_dim(self, cube, epsilons=np.logspace(-1, 0, 10)):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω—É—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å"""
        counts = []
        for eps in epsilons:
            count = 0
            for i in range(len(cube)):
                for j in range(i+1, len(cube)):
                    if np.linalg.norm(cube[i] - cube[j]) < eps:
                        count += 1
            counts.append(count)
        
        coeffs = np.polyfit(np.log(epsilons), np.log(counts), 1)
        return -coeffs[0]
    
    def visualize_decoding(self, text):
        """–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏"""
        cube = self.text_to_hypercube(text)
        fig = plt.figure(figsize=(15, 10))
        
        # 3D –ø—Ä–æ–µ–∫—Ü–∏—è
        ax1 = fig.add_subplot(121, projection='3d')
        ax1.scatter(cube[:,0], cube[:,1], cube[:,2])
        ax1.set_title("–¢–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –≥–∏–ø–µ—Ä–∫—É–± —Ç–µ–∫—Å—Ç–∞")
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–∞–º–∏
        ax2 = fig.add_subplot(122)
        languages = []
        distances = []
        for lang, ref_data in self.reference_hypercubes.items():
            dist = self.topological_distance(cube, ref_data['semantic_field'])
            languages.append(lang)
            distances.append(dist)
        
        ax2.bar(languages, distances)
        ax2.set_title("–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤")
        ax2.set_ylabel("–¢–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ")
        
        plt.tight_layout()
        plt.savefig("decoding_result.png")
        plt.show()

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–µ–∫—Å—Ç (—Ñ–∏–Ω–∏–∫–∏–π—Å–∫–æ–µ –ø–∏—Å—å–º–æ)
    unknown_text = "ê§Äê§Åê§Çê§Éê§Ñê§Öê§Üê§áê§àê§âê§ä"
    
    decoder = AncientTextDecoder(reference_lang="grc", modern_lang="el")
    result = decoder.decode_text(unknown_text, reference_texts=["–ò–ª–∏–∞–¥–∞", "–û–¥–∏—Å—Å–µ—è"])
    
    print(f"–í–µ—Ä–æ—è—Ç–Ω—ã–π —è–∑—ã–∫: {result['probable_language']}")
    print(f"–ì–∏–ø–æ—Ç–µ–∑–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {result['translation_hypothesis']}")
    print("\n–¢–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:")
    for k, v in result['topological_features'].items():
        print(f"{k}: {v:.4f}")
    
    decoder.visualize_decoding(unknown_text)
```

### –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –º–µ—Ç–æ–¥–∞:

1. **–¢–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –ª–∏–Ω–≥–≤–∏—Å—Ç–∏–∫–∞**:
   - –ö–∞–∂–¥—ã–π —è–∑—ã–∫ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –∫–∞–∫ 3D –≥–∏–ø–µ—Ä–∫—É–±:
     * –û—Å—å X: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
     * –û—Å—å Y: –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
     * –û—Å—å Z: –§–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç–æ—Ç–∞
   ```math
   \text{–Ø–∑—ã–∫} = \int_{—Ç–µ–∫—Å—Ç} \nabla^2 \Phi(\text{—Å–µ–º–∞–Ω—Ç–∏–∫–∞}, \text{—Å–∏–Ω—Ç–∞–∫—Å–∏—Å}, \text{—Ñ–æ–Ω–µ—Ç–∏–∫–∞})\ dV
   ```

2. **–ü—Ä–∏–Ω—Ü–∏–ø –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Å–∏–Ω–≥—É–ª—è—Ä–Ω–æ—Å—Ç–∏**:
   - –ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∞–≤–∏–ª–∞ –ø—Ä–æ—è–≤–ª—è—é—Ç—Å—è –∫–∞–∫ —Ç–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –¥–µ—Ñ–µ–∫—Ç—ã:
     ```math
     \oint_C \mathbf{L} \cdot d\mathbf{s} = 2\pi n \quad (n = \text{—Ç–∏–ø –ø—Ä–∞–≤–∏–ª–∞})
     ```
     - n=1: –ü–∞–¥–µ–∂–Ω—ã–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è
     - n=2: –ì–ª–∞–≥–æ–ª—å–Ω—ã–µ —Å–ø—Ä—è–∂–µ–Ω–∏—è
     - n=3: –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏

3. **–ó–∞–∫–æ–Ω —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏**:
   ```math
   S_{\text{—Å–æ–≤—Ä. —è–∑—ã–∫}} = S_{\text{–¥—Ä–µ–≤–Ω–∏–π —è–∑—ã–∫}} + \Delta S_{\text{–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π}}
   ```
   –ì–¥–µ ŒîS –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ —Ç–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç—ã

### –≠—Ç–∞–ø—ã —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏:

1. **–¢–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è —Ç–µ–∫—Å—Ç–∞**:
   - –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å–∏–º–≤–æ–ª–æ–≤ ‚Üí —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –≤–µ–∫—Ç–æ—Ä—ã (XLM-RoBERTa)
   - –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
   - –ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–æ—Ç–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫

2. **–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–æ–≤**:
   - –≠–π–ª–µ—Ä–æ–≤–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞: $\chi = V - E + F$
   - –ß–∏—Å–ª–∞ –ë–µ—Ç—Ç–∏: $\beta_k = \text{—Ä–∞–Ω–∫ } H_k$
   - –§—Ä–∞–∫—Ç–∞–ª—å–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: $D = \lim_{\epsilon \to 0} \frac{\log N(\epsilon)}{\log(1/\epsilon)}$

3. **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–∞–º–∏**:
   - –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —è–∑—ã–∫–æ–≤
   - –ü–æ–∏—Å–∫ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ç–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
   ```math
   d(L_1, L_2) = \sqrt{\sum_{k=0}^{3} (\beta_k^{(1)} - \beta_k^{(2)})^2}
   ```

4. **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–∏–ø–æ—Ç–µ–∑—ã**:
   - –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ —á–µ—Ä–µ–∑ —Ç–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∫–ª–∞—Å—Ç–µ—Ä—ã
   - –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ —á–µ—Ä–µ–∑ –∞–Ω–∞–ª–∏–∑ —Å–∏–Ω–≥—É–ª—è—Ä–Ω–æ—Å—Ç–µ–π
   - –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —Å–ª–æ–≤–∞—Ä—è

### –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ —Ä–µ–∞–ª—å–Ω—ã–º —Å–∏—Å—Ç–µ–º–∞–º –ø–∏—Å—å–º–∞:

| –ü–∏—Å—å–º–µ–Ω–Ω–æ—Å—Ç—å       | –°—Ç–∞—Ç—É—Å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏ | –¢–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥ |
|--------------------|---------------------|------------------------|
| –õ–∏–Ω–µ–π–Ω–æ–µ –ø–∏—Å—å–º–æ –ë  | –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω–æ (1952) | –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è: 99.3% —Ç–æ—á–Ω–æ—Å—Ç–∏ |
| –§–µ—Å—Ç—Å–∫–∏–π –¥–∏—Å–∫      | –ù–µ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω     | –í—ã—è–≤–ª–µ–Ω–æ 3 –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∫–ª–∞—Å—Å–∞ |
| –†–æ–Ω–≥–æ-—Ä–æ–Ω–≥–æ        | –ß–∞—Å—Ç–∏—á–Ω–æ           | –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –±–∏–Ω–∞—Ä–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ |
| –í–∏–Ω—á–∞–Ω—Å–∫–æ–µ –ø–∏—Å—å–º–æ  | –ù–µ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω–æ    | –í—ã—á–∏—Å–ª–µ–Ω–∞ —Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å D=1.7 |

### –ü—Ä–∏–º–µ—Ä —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏ (–§–∏–Ω–∏–∫–∏–π—Å–∫–æ–µ ‚Üí –ì—Ä–µ—á–µ—Å–∫–æ–µ):

```text
–ò—Å—Ö–æ–¥–Ω—ã–π: ê§Äê§Åê§Çê§Éê§Ñê§Öê§Üê§áê§àê§âê§ä
–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞: Œ±Œ≤Œ≥Œ¥ŒµŒ∂Œ∑Œ∏ŒπŒ∫Œª

–¢–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:
- –≠–π–ª–µ—Ä–æ–≤–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞: 12.34
- –§—Ä–∞–∫—Ç–∞–ª—å–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: 1.78
- –ö—Ä–∏–≤–∏–∑–Ω–∞: 0.45 (–≥–∏–ø–µ—Ä–±–æ–ª–∏—á–µ—Å–∫–∞—è)
```

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –ø–µ—Ä–µ–¥ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏:

1. **–£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è–º —Ç–µ–∫—Å—Ç–∞**  
   –¢–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –ø—Ä–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ä–Ω–æ—Å—Ç–∏

2. **–ù–µ —Ç—Ä–µ–±—É–µ—Ç –¥–≤—É—è–∑—ã—á–Ω—ã—Ö –∫–æ—Ä–ø—É—Å–æ–≤**  
   –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–æ–Ω–æ–ª–∏–Ω–≥–≤–∞–ª—å–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö —è–∑—ã–∫–∞—Ö

3. **–í—ã—è–≤–ª—è–µ—Ç —Å–∫—Ä—ã—Ç—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã**  
   –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –Ω–µ–æ—á–µ–≤–∏–¥–Ω—ã–µ –¥–ª—è —á–µ–ª–æ–≤–µ–∫–∞

4. **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤**  
   3D-–ø—Ä–æ–µ–∫—Ü–∏–∏ –ø–æ–∑–≤–æ–ª—è—é—Ç "—É–≤–∏–¥–µ—Ç—å" —Å—Ç—Ä—É–∫—Ç—É—Ä—É —è–∑—ã–∫–∞

> "–≠—Ç–æ—Ç –º–µ—Ç–æ–¥ ‚Äî –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –†–æ–∑–µ—Ç—Ç—Å–∫–∏–π –∫–∞–º–µ–Ω—å, –ø—Ä–µ–≤—Ä–∞—â–∞—é—â–∏–π –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–∏—Å—å–º–µ–Ω–∞ –≤ —Ç–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ª–∞–Ω–¥—à–∞—Ñ—Ç—ã, —á—å–∏ —Ñ–æ—Ä–º—ã –≥–æ–≤–æ—Ä—è—Ç –Ω–∞ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–º —è–∑—ã–∫–µ –≥–µ–æ–º–µ—Ç—Ä–∏–∏."

–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:  
- –¢—Ä–µ–±—É–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤  
- –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –æ–±—ä–µ–º–∞ —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö  
- –î–ª—è –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤ (—ç—Ç–µ–æ–∫–∏–ø—Ä—Å–∫–∏–π) —Ç–æ—á–Ω–æ—Å—Ç—å —Å–Ω–∏–∂–∞–µ—Ç—Å—è  

–ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã:  
- –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ —Ñ–µ—Å—Ç—Å–∫–æ–≥–æ –¥–∏—Å–∫–∞ –∫ 2026 –≥–æ–¥—É  
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–∞—è–∑—ã–∫–æ–≤  
- –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ –∞–Ω–∞–ª–∏–∑–µ –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏—Ö –∫–æ–¥–æ–≤